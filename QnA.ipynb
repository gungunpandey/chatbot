{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f9908b-b2a3-41bc-a561-64a34150f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (1.36.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.56-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
      "  Downloading langchain_core-0.2.22-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m727.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m866.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.56 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.56-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.26-py3-none-any.whl.metadata (610 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dataclasses-json (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from llama-index-core==0.10.56->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from llama-index-core==0.10.56->llama-index) (10.4.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core==0.10.56->llama-index)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from pdfminer.six) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
      "  Downloading cryptography-43.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-cloud>=0.0.9 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
      "  Downloading llama_cloud-0.0.9-py3-none-any.whl.metadata (750 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain) (3.0.0)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.56->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.56->llama-index)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index-0.10.56-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.10.56-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading cryptography-43.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl (9.3 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.26-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading llama_cloud-0.0.9-py3-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: striprtf, pytz, dirtyjson, wrapt, tzdata, tenacity, regex, pypdf, orjson, numpy, networkx, mypy-extensions, multidict, marshmallow, jsonpatch, joblib, greenlet, fsspec, frozenlist, click, async-timeout, yarl, typing-inspect, tiktoken, SQLAlchemy, pandas, nltk, deprecated, cryptography, aiosignal, pdfminer.six, llama-cloud, langsmith, dataclasses-json, aiohttp, llama-index-legacy, llama-index-core, langchain-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 click-8.1.7 cryptography-43.0.0 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 joblib-1.4.2 jsonpatch-1.33 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 llama-cloud-0.0.9 llama-index-0.10.56 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.12 llama-index-core-0.10.56 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.26 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 orjson-3.10.6 pandas-2.2.2 pdfminer.six-20240706 pypdf-4.3.1 pytz-2024.1 regex-2024.5.15 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0 tzdata-2024.1 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain llama-index pdfminer.six pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0cfae7-977e-42be-9f66-f5411cac5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNITED STATESSECURITIES AND EXCHANGE COMMISSIONWashington, D.C. 20549FORM 10-Q☒QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the quarterly period ended October 29, 2023OR☐TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934Commission file number: 0-23985NVIDIA CORPORATION(Exact name of registrant as specified in its charter)Delaware94-3177549(State or other jurisdiction of(I.R.S. Employerincorporation or organizatio\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "pdf_path = \"7df4dbdc-eb62-4d53-bc27-d334bfcb2335.pdf\"\n",
    "\n",
    "text = extract_text(pdf_path)\n",
    "print(text[:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22cc9b1-d3e0-408d-a89d-1cb7706a7b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7328cae8-0cd2-48eb-a9fa-08f01150d92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7\n",
      "First chunk: UNITED STATESSECURITIES AND EXCHANGE COMMISSIONWashington, D.C. 20549FORM 10-Q☒QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the quarterly period ended October 29, 2023OR☐TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934Commission file number: 0-23985NVIDIA CORPORATION(Exact name of registrant as specified in its charter)Delaware94-3177549(State or other jurisdiction of(I.R.S. Employerincorporation or organizatio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def chunk_text(text, chunk_size=4000):\n",
    "  sentences = sent_tokenize(text)\n",
    "  chunks = []\n",
    "  current_chunk = []\n",
    "  current_length = 0\n",
    "  \n",
    "  for sentence in sentences:\n",
    "    sentence_length = len(sentence.split())\n",
    "    if current_length + sentence_length > chunk_size:\n",
    "      chunks.append(' '.join(current_chunk))\n",
    "      current_chunk = [sentence]\n",
    "      current_length = sentence_length\n",
    "    else:\n",
    "      current_chunk.append(sentence)\n",
    "      current_length += sentence_length\n",
    "  \n",
    "  if current_chunk:\n",
    "    chunks.append(' '.join(current_chunk))\n",
    "  \n",
    "  return chunks\n",
    "\n",
    "chunks = chunk_text(text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"First chunk: {chunks[0][:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5878ae-3bca-4b3d-8e28-f3e79e5d78c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 13\n",
      "the number of shares of common stock, $0.001 par value, outstanding as of November 17, 2023, was 2.47 billion . investors should monitor these accounts and the blog, in addition to following our investor relations website, press releases, SEC filings and public conference calls and webcasts.\n",
      "nviidia's balance sheet was reclassified to conform to the current fiscal year presentation . a total of $9.03 billion of aggregate unearned stock-based compensation expense was recognized for the third quarter and first nine months of fiscal year 2023 . the irs audit of our federal income tax returns for fiscal years 2018 and 2019 was resolved .\n",
      "the effective tax rate for the first nine months of fiscal year 2024 was lower than the federal statutory rate of 21% . net realized gains and losses were not significant for all periods presented . two customers each accounted for 11% of our accounts receivable balance as of October 29, 2023 .\n",
      "During the first nine months of fiscal year 2023, we had outst\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#T5 for summarization, known for handling longer text chunks\n",
    "try:\n",
    "  summarizer = pipeline(\"summarization\", model=\"t5-base\")\n",
    "except Exception as e:\n",
    "  print(f\"Error loading summarizer: {e}\")\n",
    "  summarizer = None  \n",
    "\n",
    "def summarize_chunk(chunk):\n",
    "  if summarizer is not None:\n",
    "    max_length = 256  \n",
    "    try:\n",
    "      summary = summarizer(chunk, max_length=max_length, min_length=25, do_sample=False)\n",
    "      return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "      print(f\"Error summarizing chunk '{chunk[:50]}...': {e}\")\n",
    "      return \"Error during summarization.\"\n",
    "  else:\n",
    "    return \"Summarization pipeline failed to load.\"\n",
    "\n",
    "def chunk_text(text, chunk_size=2000):  \n",
    "  sentences = sent_tokenize(text)\n",
    "  chunks = []\n",
    "  current_chunk = []\n",
    "  current_length = 0\n",
    "  \n",
    "  for sentence in sentences:\n",
    "    sentence_length = len(sentence.split())\n",
    "    if current_length + sentence_length > chunk_size:\n",
    "      chunks.append(' '.join(current_chunk))\n",
    "      current_chunk = [sentence]\n",
    "      current_length = sentence_length\n",
    "    else:\n",
    "      current_chunk.append(sentence)\n",
    "      current_length += sentence_length\n",
    "  \n",
    "  if current_chunk:\n",
    "    chunks.append(' '.join(current_chunk))\n",
    "  \n",
    "  return chunks\n",
    "\n",
    "chunks = chunk_text(text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "summaries = [summarize_chunk(chunk) for chunk in chunks]\n",
    "full_summary = \"\\n\".join(summaries)\n",
    "print(full_summary[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291fadd8-0ce2-4e33-9a67-8538c5b00c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "# Convert summaries to LangChain Documents\n",
    "documents = [Document(page_content=summary) for summary in summaries]\n",
    "\n",
    "# Initialize Hugging Face embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the FAISS vector store index\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "755d405d-5fba-451f-b6d1-798e1d90b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the QA model and tokenizer\n",
    "qa_model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)\n",
    "\n",
    "# QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a87324b-d224-4a87-9a2a-2485226d6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/chatbot-ElJdDcMS/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: $18.28 billion in cash, cash equivalents, and marketable securities\n"
     ]
    }
   ],
   "source": [
    "def retrieve_documents(question):\n",
    "    # Use the vector store's retriever to get relevant documents\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    # Use get_relevant_documents method\n",
    "    results = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def answer_question(question):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(question)\n",
    "    \n",
    "    # Combine the contents of the retrieved documents\n",
    "    context = \" \".join(doc.page_content for doc in retrieved_docs)\n",
    "    \n",
    "    # Answer the question using the QA pipeline\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "# Example question\n",
    "question = \"What is the financial performance of NVIDIA for the quarter ended October 29, 2023?\"\n",
    "answer = answer_question(question)\n",
    "print(f'Answer: {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f55806-c5e1-487c-a6a7-d4a07d20b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_tables(text):\n",
    "    tables = []\n",
    "    # Append each table DataFrame to the tables list\n",
    "    return tables\n",
    "\n",
    "tables = preprocess_tables(text)\n",
    "\n",
    "# Convert each table to a text chunk\n",
    "table_chunks = [df.to_string() for df in tables]\n",
    "\n",
    "# Combine text and table chunks\n",
    "all_chunks = chunks + table_chunks\n",
    "\n",
    "# Summarize combined chunks\n",
    "summaries1 = [summarize_chunk(chunk) for chunk in all_chunks]\n",
    "full_summary = \"\\n\".join(summaries1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7781ee8c-8ccd-4eb6-90f2-cb2fcbff7b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cash, cash equivalents, and marketable securities\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "# Convert summaries to LangChain Documents\n",
    "documents = [Document(page_content=summary) for summary in summaries1]\n",
    "\n",
    "# Initialize Hugging Face embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the FAISS vector store index\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Define the QA model and tokenizer\n",
    "qa_model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)\n",
    "\n",
    "# QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer)\n",
    "\n",
    "def retrieve_documents(question):\n",
    "    # Use the vector store's retriever to get relevant documents\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    # Use get_relevant_documents method\n",
    "    results = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def answer_question(question):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(question)\n",
    "    \n",
    "    # Combine the contents of the retrieved documents\n",
    "    context = \" \".join(doc.page_content for doc in retrieved_docs)\n",
    "    \n",
    "    # Answer the question using the QA pipeline\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "question = \"What are the key financial metrics for NVIDIA in 2023?\"\n",
    "answer = answer_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecae6e9-4477-4159-b223-9d0d2a138205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
